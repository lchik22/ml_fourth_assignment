{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! pip install kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "\n",
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "\n",
        "!pip install -q wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elMn19twdcVr",
        "outputId": "2a2a2b7e-1ca8-488e-8adf-f71883641947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 95% 271M/285M [00:00<00:00, 525MB/s]\n",
            "100% 285M/285M [00:00<00:00, 538MB/s]\n",
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pPV5DTZ6dSwr",
        "outputId": "56ea95cf-289a-4907-df09-23974329d9cc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_082826-i7azg6i8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lchik22-free-uni/facial-expression-recognition/runs/i7azg6i8' target=\"_blank\">combined-vgg-style-net-v1.0</a></strong> to <a href='https://wandb.ai/lchik22-free-uni/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lchik22-free-uni/facial-expression-recognition' target=\"_blank\">https://wandb.ai/lchik22-free-uni/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lchik22-free-uni/facial-expression-recognition/runs/i7azg6i8' target=\"_blank\">https://wandb.ai/lchik22-free-uni/facial-expression-recognition/runs/i7azg6i8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: Train Acc=0.1593, Val Acc=0.1916, Train Loss=2.0018, Val Loss=1.9202\n",
            "New best model saved with validation accuracy: 0.1916\n",
            "Epoch 02: Train Acc=0.1744, Val Acc=0.2013, Train Loss=1.9400, Val Loss=1.9907\n",
            "New best model saved with validation accuracy: 0.2013\n",
            "Epoch 03: Train Acc=0.2173, Val Acc=0.2334, Train Loss=1.8765, Val Loss=1.7672\n",
            "New best model saved with validation accuracy: 0.2334\n",
            "Epoch 04: Train Acc=0.2874, Val Acc=0.2470, Train Loss=1.7751, Val Loss=2.0837\n",
            "New best model saved with validation accuracy: 0.2470\n",
            "Epoch 05: Train Acc=0.3525, Val Acc=0.3608, Train Loss=1.6747, Val Loss=1.5889\n",
            "New best model saved with validation accuracy: 0.3608\n",
            "Epoch 06: Train Acc=0.3788, Val Acc=0.3866, Train Loss=1.6195, Val Loss=1.5355\n",
            "New best model saved with validation accuracy: 0.3866\n",
            "Epoch 07: Train Acc=0.4037, Val Acc=0.3612, Train Loss=1.5596, Val Loss=1.5167\n",
            "Epoch 08: Train Acc=0.4218, Val Acc=0.3856, Train Loss=1.5120, Val Loss=1.4805\n",
            "Epoch 09: Train Acc=0.4411, Val Acc=0.4330, Train Loss=1.4654, Val Loss=1.3920\n",
            "New best model saved with validation accuracy: 0.4330\n",
            "Epoch 10: Train Acc=0.4545, Val Acc=0.4932, Train Loss=1.4307, Val Loss=1.3397\n",
            "New best model saved with validation accuracy: 0.4932\n",
            "Epoch 11: Train Acc=0.4706, Val Acc=0.4883, Train Loss=1.3962, Val Loss=1.4640\n",
            "Epoch 12: Train Acc=0.4719, Val Acc=0.4918, Train Loss=1.3751, Val Loss=1.2590\n",
            "Epoch 13: Train Acc=0.4911, Val Acc=0.5200, Train Loss=1.3335, Val Loss=1.2303\n",
            "New best model saved with validation accuracy: 0.5200\n",
            "Epoch 14: Train Acc=0.5052, Val Acc=0.5294, Train Loss=1.3066, Val Loss=1.2188\n",
            "New best model saved with validation accuracy: 0.5294\n",
            "Epoch 15: Train Acc=0.5138, Val Acc=0.5496, Train Loss=1.2876, Val Loss=1.2135\n",
            "New best model saved with validation accuracy: 0.5496\n",
            "Epoch 16: Train Acc=0.5197, Val Acc=0.4908, Train Loss=1.2699, Val Loss=1.2355\n",
            "Epoch 17: Train Acc=0.5277, Val Acc=0.5657, Train Loss=1.2377, Val Loss=1.1412\n",
            "New best model saved with validation accuracy: 0.5657\n",
            "Epoch 18: Train Acc=0.5346, Val Acc=0.5758, Train Loss=1.2326, Val Loss=1.1228\n",
            "New best model saved with validation accuracy: 0.5758\n",
            "Epoch 19: Train Acc=0.5400, Val Acc=0.5935, Train Loss=1.2032, Val Loss=1.1258\n",
            "New best model saved with validation accuracy: 0.5935\n",
            "Epoch 20: Train Acc=0.5442, Val Acc=0.5980, Train Loss=1.1988, Val Loss=1.1117\n",
            "New best model saved with validation accuracy: 0.5980\n",
            "Epoch 21: Train Acc=0.5535, Val Acc=0.5792, Train Loss=1.1787, Val Loss=1.1202\n",
            "Epoch 22: Train Acc=0.5560, Val Acc=0.5650, Train Loss=1.1640, Val Loss=1.1444\n",
            "Epoch 23: Train Acc=0.5641, Val Acc=0.5890, Train Loss=1.1424, Val Loss=1.0989\n",
            "Epoch 24: Train Acc=0.5617, Val Acc=0.5987, Train Loss=1.1416, Val Loss=1.0755\n",
            "New best model saved with validation accuracy: 0.5987\n",
            "Epoch 25: Train Acc=0.5740, Val Acc=0.6019, Train Loss=1.1177, Val Loss=1.0507\n",
            "New best model saved with validation accuracy: 0.6019\n",
            "Epoch 26: Train Acc=0.5759, Val Acc=0.5803, Train Loss=1.0925, Val Loss=1.1007\n",
            "Epoch 27: Train Acc=0.5739, Val Acc=0.6015, Train Loss=1.1114, Val Loss=1.0929\n",
            "Epoch 28: Train Acc=0.5785, Val Acc=0.5820, Train Loss=1.0852, Val Loss=1.1264\n",
            "Epoch 29: Train Acc=0.5836, Val Acc=0.6179, Train Loss=1.0829, Val Loss=1.0782\n",
            "New best model saved with validation accuracy: 0.6179\n",
            "Epoch 30: Train Acc=0.5880, Val Acc=0.6057, Train Loss=1.0550, Val Loss=1.0694\n",
            "Epoch 31: Train Acc=0.5936, Val Acc=0.5827, Train Loss=1.0508, Val Loss=1.0789\n",
            "Epoch 32: Train Acc=0.5936, Val Acc=0.6109, Train Loss=1.0604, Val Loss=1.0397\n",
            "Epoch 33: Train Acc=0.6010, Val Acc=0.6224, Train Loss=1.0407, Val Loss=1.0308\n",
            "New best model saved with validation accuracy: 0.6224\n",
            "Epoch 34: Train Acc=0.6021, Val Acc=0.6242, Train Loss=1.0292, Val Loss=1.0491\n",
            "New best model saved with validation accuracy: 0.6242\n",
            "Epoch 35: Train Acc=0.6043, Val Acc=0.6301, Train Loss=1.0161, Val Loss=1.0346\n",
            "New best model saved with validation accuracy: 0.6301\n",
            "Epoch 36: Train Acc=0.6024, Val Acc=0.6228, Train Loss=1.0185, Val Loss=1.0782\n",
            "Epoch 37: Train Acc=0.6041, Val Acc=0.6318, Train Loss=1.0178, Val Loss=1.0644\n",
            "New best model saved with validation accuracy: 0.6318\n",
            "Epoch 38: Train Acc=0.6192, Val Acc=0.6169, Train Loss=0.9827, Val Loss=1.0221\n",
            "Epoch 39: Train Acc=0.6165, Val Acc=0.6315, Train Loss=0.9930, Val Loss=1.1540\n",
            "Epoch 40: Train Acc=0.6148, Val Acc=0.6325, Train Loss=0.9770, Val Loss=1.0153\n",
            "New best model saved with validation accuracy: 0.6325\n",
            "Epoch 41: Train Acc=0.6265, Val Acc=0.6336, Train Loss=0.9574, Val Loss=1.0420\n",
            "New best model saved with validation accuracy: 0.6336\n",
            "Epoch 42: Train Acc=0.6240, Val Acc=0.6284, Train Loss=0.9488, Val Loss=1.0594\n",
            "Epoch 43: Train Acc=0.6245, Val Acc=0.6196, Train Loss=0.9633, Val Loss=1.0115\n",
            "Epoch 44: Train Acc=0.6250, Val Acc=0.6301, Train Loss=0.9549, Val Loss=1.0771\n",
            "Epoch 45: Train Acc=0.6328, Val Acc=0.6315, Train Loss=0.9307, Val Loss=1.0660\n",
            "Epoch 46: Train Acc=0.6339, Val Acc=0.6458, Train Loss=0.9327, Val Loss=0.9694\n",
            "New best model saved with validation accuracy: 0.6458\n",
            "Epoch 47: Train Acc=0.6371, Val Acc=0.6444, Train Loss=0.9216, Val Loss=1.1272\n",
            "Epoch 48: Train Acc=0.6332, Val Acc=0.6371, Train Loss=0.9348, Val Loss=1.0245\n",
            "Epoch 49: Train Acc=0.6392, Val Acc=0.6416, Train Loss=0.9151, Val Loss=1.0594\n",
            "Epoch 50: Train Acc=0.6398, Val Acc=0.6426, Train Loss=0.9176, Val Loss=1.0147\n",
            "Epoch 51: Train Acc=0.6479, Val Acc=0.6475, Train Loss=0.8966, Val Loss=1.1316\n",
            "New best model saved with validation accuracy: 0.6475\n",
            "Epoch 52: Train Acc=0.6459, Val Acc=0.6322, Train Loss=0.8836, Val Loss=1.0358\n",
            "Epoch 53: Train Acc=0.6470, Val Acc=0.6398, Train Loss=0.8857, Val Loss=1.0391\n",
            "Epoch 54: Train Acc=0.6528, Val Acc=0.6444, Train Loss=0.8785, Val Loss=1.0203\n",
            "Epoch 55: Train Acc=0.6568, Val Acc=0.6506, Train Loss=0.8570, Val Loss=1.0099\n",
            "New best model saved with validation accuracy: 0.6506\n",
            "Epoch 56: Train Acc=0.6542, Val Acc=0.6524, Train Loss=0.8789, Val Loss=1.0237\n",
            "New best model saved with validation accuracy: 0.6524\n",
            "Epoch 57: Train Acc=0.6588, Val Acc=0.6392, Train Loss=0.8622, Val Loss=1.0394\n",
            "Epoch 58: Train Acc=0.6592, Val Acc=0.6524, Train Loss=0.8526, Val Loss=1.0482\n",
            "Epoch 59: Train Acc=0.6656, Val Acc=0.6458, Train Loss=0.8471, Val Loss=1.0371\n",
            "Epoch 60: Train Acc=0.6648, Val Acc=0.6698, Train Loss=0.8498, Val Loss=0.9938\n",
            "New best model saved with validation accuracy: 0.6698\n",
            "Epoch 61: Train Acc=0.6699, Val Acc=0.6600, Train Loss=0.8353, Val Loss=1.0969\n",
            "Epoch 62: Train Acc=0.6685, Val Acc=0.6635, Train Loss=0.8266, Val Loss=1.0947\n",
            "Epoch 63: Train Acc=0.6664, Val Acc=0.6520, Train Loss=0.8331, Val Loss=1.1901\n",
            "Epoch 64: Train Acc=0.6727, Val Acc=0.6628, Train Loss=0.8159, Val Loss=1.0785\n",
            "Epoch 65: Train Acc=0.6766, Val Acc=0.6517, Train Loss=0.8119, Val Loss=1.0692\n",
            "Epoch 66: Train Acc=0.6741, Val Acc=0.6499, Train Loss=0.8185, Val Loss=1.0092\n",
            "Epoch 67: Train Acc=0.6957, Val Acc=0.6660, Train Loss=0.7657, Val Loss=1.0316\n",
            "Epoch 68: Train Acc=0.6974, Val Acc=0.6642, Train Loss=0.7527, Val Loss=1.0624\n",
            "Epoch 69: Train Acc=0.7013, Val Acc=0.6715, Train Loss=0.7386, Val Loss=1.0213\n",
            "New best model saved with validation accuracy: 0.6715\n",
            "Epoch 70: Train Acc=0.7064, Val Acc=0.6667, Train Loss=0.7271, Val Loss=1.0865\n",
            "Epoch 71: Train Acc=0.7046, Val Acc=0.6733, Train Loss=0.7319, Val Loss=1.0501\n",
            "New best model saved with validation accuracy: 0.6733\n",
            "Epoch 72: Train Acc=0.7069, Val Acc=0.6764, Train Loss=0.7238, Val Loss=1.0478\n",
            "New best model saved with validation accuracy: 0.6764\n",
            "Epoch 73: Train Acc=0.7175, Val Acc=0.6792, Train Loss=0.7034, Val Loss=1.0987\n",
            "New best model saved with validation accuracy: 0.6792\n",
            "Epoch 74: Train Acc=0.7155, Val Acc=0.6750, Train Loss=0.7117, Val Loss=1.0994\n",
            "Epoch 75: Train Acc=0.7175, Val Acc=0.6761, Train Loss=0.7005, Val Loss=1.1163\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>learning_rate</td><td>█████████████████████████████████████▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>██▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▄▃▅▅▆▆▅▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_loss</td><td>▇█▅▃▃▃▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>75</td></tr><tr><td>learning_rate</td><td>0.0005</td></tr><tr><td>train_accuracy</td><td>0.71751</td></tr><tr><td>train_loss</td><td>0.70047</td></tr><tr><td>val_accuracy</td><td>0.67607</td></tr><tr><td>val_loss</td><td>1.11631</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">combined-vgg-style-net-v1.0</strong> at: <a href='https://wandb.ai/lchik22-free-uni/facial-expression-recognition/runs/i7azg6i8' target=\"_blank\">https://wandb.ai/lchik22-free-uni/facial-expression-recognition/runs/i7azg6i8</a><br> View project at: <a href='https://wandb.ai/lchik22-free-uni/facial-expression-recognition' target=\"_blank\">https://wandb.ai/lchik22-free-uni/facial-expression-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_082826-i7azg6i8/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Initialize W&B and Configuration\n",
        "wandb.init(project=\"facial-expression-recognition\", name=\"combined-vgg-style-net-v1.0\")\n",
        "\n",
        "config = {\n",
        "    \"epochs\": 75,  # A deeper model with augmentation needs more epochs to train\n",
        "    \"batch_size\": 64,  # A larger model may require a smaller batch size to fit in memory\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"image_size\": 48,\n",
        "    \"num_classes\": 7,\n",
        "    \"num_workers\": 2\n",
        "}\n",
        "wandb.config.update(config)\n",
        "\n",
        "# Data Loading and Efficient Pre-processing\n",
        "# Process pixel strings once for speed.\n",
        "def string_to_array(pixel_string):\n",
        "    return np.array(pixel_string.split(), dtype=np.uint8).reshape(config[\"image_size\"], config[\"image_size\"])\n",
        "\n",
        "data_path = os.path.expanduser(\"/content/train.csv\")\n",
        "if not os.path.exists(data_path):\n",
        "    print(f\"Error: Data file not found at {data_path}\")\n",
        "    pass\n",
        "\n",
        "full_train_df = pd.read_csv(data_path)\n",
        "full_train_df['pixels_array'] = full_train_df['pixels'].apply(string_to_array)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    full_train_df,\n",
        "    test_size=0.1,\n",
        "    stratify=full_train_df['emotion'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Dataset Class\n",
        "class FacialExpressionDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_array = self.df.iloc[idx]['pixels_array']\n",
        "        image = Image.fromarray(image_array)\n",
        "        label = int(self.df.iloc[idx]['emotion'])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Rich Data Augmentation\n",
        "# Crucial for preventing the large model from overfitting.\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = FacialExpressionDataset(train_df, transform=train_transform)\n",
        "val_dataset = FacialExpressionDataset(val_df, transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
        "    num_workers=config[\"num_workers\"], pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=config[\"batch_size\"], shuffle=False,\n",
        "    num_workers=config[\"num_workers\"], pin_memory=True\n",
        ")\n",
        "\n",
        "# Model Architecture\n",
        "# We take the deep VGG-style feature extractor\n",
        "# and combine it with the robust classifier head.\n",
        "class CombinedVGGNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CombinedVGGNet, self).__init__()\n",
        "\n",
        "        # The powerful feature extractor\n",
        "        self.features = nn.Sequential(\n",
        "          # Block 1\n",
        "          nn.Conv2d(1, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),  # -> (64, 24, 24)\n",
        "\n",
        "          # Block 2\n",
        "          nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),  # -> (128, 12, 12)\n",
        "\n",
        "          # Block 3\n",
        "          nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),  # -> (256, 6, 6)\n",
        "\n",
        "          # Block 4\n",
        "          nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),  # -> (512, 3, 3)\n",
        "        )\n",
        "\n",
        "        # The robust classifier head, adapted for the 512 channels\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # Pool to a single 1x1 feature map\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 1 * 1, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CombinedVGGNet(num_classes=config[\"num_classes\"]).to(device)\n",
        "\n",
        "# Loss, Optimizer, and Scheduler\n",
        "# Handle class imbalance and adapt the learning rate.\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_df['emotion']), y=train_df['emotion'].to_numpy())\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "# Full Training and Validation Loop\n",
        "wandb.watch(model, log=\"all\")\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "    model.train()\n",
        "    train_loss, train_correct = 0.0, 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_correct += (preds == labels).sum().item()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, val_correct = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_acc = train_correct / len(train_loader.dataset)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_accuracy\": train_acc,\n",
        "        \"val_loss\": val_loss, \"val_accuracy\": val_acc, \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}, Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_combined_model.pth\")\n",
        "        wandb.save(\"best_combined_model.pth\")\n",
        "        print(f\"New best model saved with validation accuracy: {val_acc:.4f}\")\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ]
}